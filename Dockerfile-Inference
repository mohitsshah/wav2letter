# ==================================================================
# wav2letter build
#
# Should be run from within existing wav2letter directory. That directory
# is copied to the docker image. The image build with wav2letter-libraries,
# and inference-pipeline only, without Flashlight or CUDA dependencies.
# wav2letter executables are at /root/wav2letter/build. The inference executable
# examples are at: /root/wav2letter/build/inference/inference/examples/
# ------------------------------------------------------------------

FROM wav2letter/wav2letter:inference-base-latest

RUN apt update && apt install -y libssl-dev && \
    wget https://github.com/Kitware/CMake/releases/download/v3.16.5/cmake-3.16.5.tar.gz && \
    tar -zxvf cmake-3.16.5.tar.gz && \
    cd cmake-3.16.5 && \
    ./bootstrap && \
    make -j2 && make install && \
    cd /root && \
    git clone --recurse-submodules -b v1.33.1 https://github.com/grpc/grpc && \
    cd grpc && mkdir -p build && cd build && \
    cmake -DCMAKE_BUILD_TYPE=Release -DgRPC_INSTALL=ON .. && \
    make -j2 && make install

# Copy wav2letter src directory from host.
RUN mkdir /root/wav2letter

COPY . /root/wav2letter

# build w2l
RUN export KENLM_ROOT_DIR=/root/kenlm && \
    export MKLROOT=/opt/intel/mkl && \
    cd /root/wav2letter && \
    mkdir -p build && \
    cd build && \
    rm -rf * && \
    cmake .. -DCMAKE_BUILD_TYPE=Release -DW2L_BUILD_LIBRARIES_ONLY=ON -DW2L_LIBRARIES_USE_CUDA=OFF -DW2L_BUILD_INFERENCE=ON   && \
    make -j$(nproc) server

EXPOSE 50051

WORKDIR /root/wav2letter

CMD ["./build/inference/inference/examples/server", "--input_files_base_path", "/root/model"]